{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladLozkin/deep/blob/master/melanoma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwCrg6qGhorq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "from shutil import copyfile\n",
        "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
        "from os import listdir, makedirs, getcwd, remove\n",
        "from PIL import Image\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as func\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "import random \n",
        "from glob import glob\n",
        "import datetime\n",
        "# from clsutils import *\n",
        "\n",
        "import sys\n",
        "print('__Python VERSION:', sys.version)\n",
        "print('__pyTorch VERSION:', torch.__version__)\n",
        "print('__CUDA VERSION')\n",
        "from subprocess import call\n",
        "# call([\"nvcc\", \"--version\"]) does not work\n",
        "! nvcc --version\n",
        "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
        "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
        "print('__Devices')\n",
        "# call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
        "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
        "\n",
        "print ('Available devices ', torch.cuda.device_count())\n",
        "print ('Current cuda device ', torch.cuda.current_device())\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "# use_cuda = False\n",
        "\n",
        "print(\"USE CUDA=\" + str (use_cuda))\n",
        "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
        "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
        "Tensor = FloatTensor\n",
        "\n",
        "manualSeed = None\n",
        "def fixSeed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if use_cuda:\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "if manualSeed is None:\n",
        "        manualSeed = 999\n",
        "fixSeed(manualSeed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ht_iP51hs4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os,sys,inspect\n",
        "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
        "parentdir = os.path.dirname(currentdir)\n",
        "sys.path.insert(0,parentdir) \n",
        "\n",
        "to_tensor = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "\n",
        "def default_loader_scale(input_path, size=150):\n",
        "    input_image = (Image.open(input_path)).convert('RGB')\n",
        "    if size is not None:\n",
        "        input_image = input_image.resize((size, size), Image.ANTIALIAS)\n",
        "    return input_image\n",
        "\n",
        "\n",
        "def default_loader(input_path):\n",
        "    input_image = (Image.open(input_path)).convert('RGB')\n",
        "    return input_image\n",
        "\n",
        "class RandomErasing(object):\n",
        "    def __init__(self, EPSILON = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3, mean=[0.4914, 0.4822, 0.4465]):\n",
        "        self.EPSILON = EPSILON\n",
        "        self.mean = mean\n",
        "        self.sl = sl\n",
        "        self.sh = sh\n",
        "        self.r1 = r1\n",
        "       \n",
        "    def __call__(self, img):\n",
        "\n",
        "        if random.uniform(0, 1) > self.EPSILON:\n",
        "            return img\n",
        "\n",
        "        for attempt in range(100):\n",
        "            area = img.size()[1] * img.size()[2]\n",
        "       \n",
        "            target_area = random.uniform(self.sl, self.sh) * area\n",
        "            aspect_ratio = random.uniform(self.r1, 1/self.r1)\n",
        "\n",
        "            h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
        "            w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
        "\n",
        "            if w <= img.size()[2] and h <= img.size()[1]:\n",
        "                x1 = random.randint(0, img.size()[1] - h)\n",
        "                y1 = random.randint(0, img.size()[2] - w)\n",
        "                if img.size()[0] == 3:\n",
        "                    #img[0, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n",
        "                    #img[1, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n",
        "                    #img[2, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n",
        "                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n",
        "                    img[1, x1:x1+h, y1:y1+w] = self.mean[1]\n",
        "                    img[2, x1:x1+h, y1:y1+w] = self.mean[2]\n",
        "                    #img[:, x1:x1+h, y1:y1+w] = torch.from_numpy(np.random.rand(3, h, w))\n",
        "                else:\n",
        "                    img[0, x1:x1+h, y1:y1+w] = self.mean[1]\n",
        "                    # img[0, x1:x1+h, y1:y1+w] = torch.from_numpy(np.random.rand(1, h, w))\n",
        "                return img\n",
        "\n",
        "        return img\n",
        "\n",
        "# from clsmodels import *\n",
        "# from clsdataset import *\n",
        "# from clstransforms import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7a4aPtFhukz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ISIC2018Dataset(Dataset):\n",
        "    def __init__(self, labels, root_dir, transform=None):\n",
        "        self.labels = labels\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.labels.iloc[idx, 0]  # file name\n",
        "        img_name = self.labels.iloc[idx, :].loc['file']\n",
        "        fullname = ''.join(['../input/ISIC2018_Task3_Training_Input/', img_name, '.jpg'])\n",
        "        image = default_loader(fullname)\n",
        "        labels = self.labels.iloc[idx, :].loc['category_id']\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, labels\n",
        "\n",
        "    @staticmethod\n",
        "    def find_classes_melanoma(fullDir):\n",
        "\n",
        "        df_labels = pd.read_csv(\"melanoma_labels.csv\", sep=',')\n",
        "        class_to_idx = {'MEL': 0,'NV' :1, 'BCC' :2 ,'AKIEC' :3, 'BKL' :4, 'DF' :5 ,'VASC' :6}\n",
        "        num_to_class = {0 :'MEL',1: 'NV', 2: 'BCC' ,3: 'AKIEC', 4: 'BKL', 5: 'DF' ,6: 'VASC'}\n",
        "        df_labels['category_id'] = np.argmax(df_labels.iloc[:,1:].values,axis=1)\n",
        "        df_labels['category'] = [num_to_class[x] for x in df_labels['category_id']]\n",
        "        #\n",
        "        # classes = [d for d in os.listdir(fullDir) if os.path.isdir(os.path.join(fullDir, d))]\n",
        "        classes = {'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'}\n",
        "\n",
        "        print('Classes: {}'.format(classes))\n",
        "        print('class_to_idx: {}'.format(class_to_idx))\n",
        "        print('num_to_class: {}'.format(num_to_class))\n",
        "\n",
        "        df = df_labels.loc[:,['image', 'category', 'category_id']]\n",
        "        df = df.rename(columns={'image':'file'})\n",
        "        df.to_csv('full_melanoma_labels.csv', index=None)\n",
        "        return classes, class_to_idx, num_to_class, df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ81M17OhwCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset='ISIC2018_Task3_Training_Input' # bone , cat-dog   d:/db/data/cat-dog/train/ ISIC2017 d:\\db\\data\\IDC_regular_ps50_idx5\\\n",
        "data_dir= '../input/' +  dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ9J1Y7Nhxck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imageList = glob(data_dir + '/**/*.jpg', recursive=True)\n",
        "print ( \"Number of images: {}\". format (len (imageList)))\n",
        "for img in imageList[0:5]:\n",
        "    print(img)\n",
        "    \n",
        "pil_im = Image.open(imageList[0], 'r')\n",
        "plt.imshow(np.asarray(pil_im))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzRs-kmDhy7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes, class_to_idx, num_to_class, df =ISIC2018Dataset.find_classes_melanoma(data_dir)\n",
        "pd.set_option('max_colwidth', 60)\n",
        "print (classes)\n",
        "print (class_to_idx)\n",
        "print (num_to_class)\n",
        "print (df.head(10))\n",
        "df.category.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwPwCfq0h1QZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_dir = '../input/ISIC2018_Task3_Training_Input/'\n",
        "plt.rcParams['figure.figsize'] = (15.0, 15.0)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.3)\n",
        "for i in range(35):\n",
        "    l,c = df.loc[df.category_id==i//5,['file','category']].iloc[i%5]\n",
        "    pil_im = Image.open(img_dir+l+'.jpg', 'r')        \n",
        "    plt.subplot(7, 5, i+1).set_title(l + ' - ' + c)\n",
        "    plt.imshow(np.asarray(pil_im)); \n",
        "    plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSj5itOih2_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ax = df.category.value_counts().plot(kind='bar',figsize=(12,4))\n",
        "ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=-45,fontsize=14)\n",
        "_ = ax.set_title('class distribution training set',fontsize=26)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bgfCJT5h4Ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 224\n",
        "\n",
        "# adapted from https://github.com/kuangliu/pytorch-retinanet/blob/master/transform.py\n",
        "# https://github.com/mratsim/Amazon-Forest-Computer-Vision/blob/master/src/p_data_augmentation.py\n",
        "normalize_img = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "\n",
        "\n",
        "train_trans = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(image_size),\n",
        "#     PowerPIL(),\n",
        "    transforms.ToTensor(),\n",
        "#     normalize_img,\n",
        "#     RandomErasing()\n",
        "])\n",
        "\n",
        "## Normalization only for validation and test\n",
        "valid_trans = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(image_size),\n",
        "    transforms.ToTensor(),\n",
        "#     normalize_img\n",
        "])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "full_data = df.sample(frac=0.95) # save for testing (not validation)\n",
        "# full_data = full_data.sample(frac=0.10) # DATA SET IS quite large use a sample first to verify process flow\n",
        "\n",
        "test_data = df[~df['file'].isin(full_data['file'])]\n",
        "test_set = ISIC2018Dataset(test_data, data_dir, transform = valid_trans)\n",
        "\n",
        "# Train validation split\n",
        "train_data = full_data.sample(frac=0.9)\n",
        "valid_data = full_data[~full_data['file'].isin(train_data['file'])]\n",
        "train_set = ISIC2018Dataset(train_data, '', transform = train_trans)\n",
        "valid_set = ISIC2018Dataset(valid_data, '', transform = valid_trans)\n",
        "        \n",
        "\n",
        "t_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "v_loader = DataLoader(valid_set, batch_size=batch_size//8, shuffle=True, num_workers=0)\n",
        "test_loader  = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "dataset_sizes = {\n",
        "    'train': len(t_loader.dataset), \n",
        "    'valid': len(v_loader.dataset),\n",
        "    'test': len(test_loader.dataset)\n",
        "}\n",
        "print ('dataset sizes:')\n",
        "print (dataset_sizes)\n",
        "fig,ax = plt.subplots(2,1,figsize=(12,12))\n",
        "ax[0] = train_data['category'].value_counts().plot(kind='bar',ax=ax[0])\n",
        "ax[0].set_xticklabels(ax[0].xaxis.get_majorticklabels(), rotation=-45,fontsize=10)\n",
        "_ = ax[0].set_title('class distribution (reduced) training set',fontsize=18)\n",
        "ax[1] = valid_data['category'].value_counts().plot(kind='bar',ax=ax[1])\n",
        "ax[1].set_xticklabels(ax[1].xaxis.get_majorticklabels(), rotation=-45,fontsize=10)\n",
        "_ = ax[1].set_title('class distribution validation set',fontsize=18)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGjGQKdWh56W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NOW_TIME = datetime.datetime.now()\n",
        "NOW_TIME =NOW_TIME.strftime(\"%Y-%m-%d %H:%M\")\n",
        "\n",
        "use_tensorboard=False\n",
        "\n",
        "hms_string(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVCTSux1h66Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flaotTensorToImage(img, mean=0, std=1):\n",
        "        \"\"\"convert a tensor to an image\"\"\"\n",
        "        img = np.transpose(img.numpy(), (1, 2, 0))\n",
        "        img = (img*std+ mean)*255\n",
        "        img = img.astype(np.uint8)    \n",
        "        return img    \n",
        "    \n",
        "imagesToShow=4\n",
        "# plt.figure(figsize=[10,10])\n",
        "for i, data in enumerate(t_loader, 0):\n",
        "    print('i=%d: '%(i))            \n",
        "    images, labels = data            \n",
        "    num = len(images)\n",
        "\n",
        "    ax = plt.subplot(2,2, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title('Sample #{}'.format(i))\n",
        "    ax.axis('off')\n",
        "\n",
        "    for n in range(num):\n",
        "        image=images[n]\n",
        "        label=labels[n]\n",
        "        plt.imshow (flaotTensorToImage(image))\n",
        "\n",
        "    if i==imagesToShow-1:\n",
        "        break  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFdZiFwuh80q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from collections import OrderedDict\n",
        "from torch.nn import init\n",
        "import numpy as np\n",
        "\n",
        "# model = SimpleNet(len(classes), 3)\n",
        "# model =vggnetXX_generic(len(classes), 3)\n",
        "# model =lenetXX_generic(len(classes), 3)\n",
        "# model =resnetxtXX_generic(len(classes), 3)\n",
        "# model =wrnXX_generic(len(classes), 3)\n",
        "# model =dpn92(len(classes))\n",
        "# model = senetXX_generic(len(classes), 3, 32)\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 7)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "lr= 0.005 * 2 * 2\n",
        "# optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9,\n",
        "                              weight_decay=0.0005, nesterov=True)\n",
        "  \n",
        "\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "# model = senetXX_generic(len(classes), 3, 32)\n",
        "model_name = (type(model).__name__) # remember the real name\n",
        "# model = torch.nn.DataParallel(model, device_ids=list(range(4)))\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "090N4K44h-sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm \n",
        "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
        "\n",
        "def train(train_loader, model, epoch, optimizer):\n",
        "    if use_cuda:\n",
        "        model.cuda()\n",
        "        criterion.cuda()\n",
        "\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    acc = AverageMeter()\n",
        "   \n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for batch_idx, (images, target) in enumerate(train_loader,0): \n",
        "        correct = 0\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if use_cuda:\n",
        "            images, target = images.cuda(), target.cuda()\n",
        "        # compute y_pred\n",
        "        y_pred = model(images)\n",
        "        loss = criterion(y_pred, target)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec1 = accuracy2(y_pred.data, target.data, topk=(1, 1))\n",
        "        losses.update(loss.data.item(), images.size(0))\n",
        "        acc.update(prec1.item(), images.size(0))\n",
        "        \n",
        "        pred = y_pred.data.max(1)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data).cpu().sum()\n",
        "        accuracy = 100. * correct / len(images)\n",
        "        \n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "        \n",
        "        if batch_idx % 1000  == 0:\n",
        "            print('TRAIN: LOSS-->{loss.val:.4f} ({loss.avg:.4f})\\t' 'ACC-->{acc.val:.3f}% ({acc.avg:.3f}%)'.format(loss=losses, acc=acc))\n",
        "            if use_tensorboard:\n",
        "                exp.add_scalar_value('tr_epoch_loss', losses.avg, step=epoch)\n",
        "                exp.add_scalar_value('tr_epoch_acc', acc.avg, step=epoch)\n",
        "                \n",
        "            print('TRAIN: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {}/{} ({:.3f}%)'.format(\n",
        "                epoch, batch_idx * len(images), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),loss.data.item(),\n",
        "                correct, len(images),\n",
        "                accuracy))            \n",
        "    \n",
        "\n",
        "    return float('{loss.avg:.4f}'.format(loss=losses)), float('{acc.avg:.4f}'.format(acc=acc))\n",
        "\n",
        "def validate(val_loader, model, epoch):\n",
        "    if use_cuda:\n",
        "        model.cuda()\n",
        "        criterion.cuda()\n",
        "\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    acc = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (images, labels) in enumerate(val_loader):\n",
        "\n",
        "        if use_cuda:\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "        # compute y_pred\n",
        "        y_pred = model(images)\n",
        "        loss = criterion(y_pred, labels)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, temp_var = accuracy2(y_pred.data, labels.data, topk=(1, 1))\n",
        "        losses.update(loss.data.item(), images.size(0))\n",
        "        acc.update(prec1.item(), images.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % 1000== 0:\n",
        "            print('VAL:   LOSS--> {loss.val:.4f} ({loss.avg:.4f})\\t''ACC-->{acc.val:.3f} ({acc.avg:.3f})'.format(\n",
        "                loss=losses, acc=acc))\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            if use_tensorboard:\n",
        "                exp.add_scalar_value('val_epoch_loss', losses.avg, step=epoch)\n",
        "                exp.add_scalar_value('val_epoch_acc', acc.avg, step=epoch)\n",
        "\n",
        "    print(' * Accuracy {acc.avg:.4f}'.format(acc=acc))\n",
        "    return float('{loss.avg:.6f}'.format(loss=losses)), float('{acc.avg:.6f}'.format(acc=acc))\n",
        "\n",
        "\n",
        "def testImageLoader(image_name):\n",
        "    \"\"\"load image, returns cuda tensor\"\"\"\n",
        "#     image = Image.open(image_name)\n",
        "    image = Image.open(image_name).convert('RGB')\n",
        "    image = test_trans(image)\n",
        "#     image = Variable(image, requires_grad=True)\n",
        "    image = image.unsqueeze(0)  \n",
        "    if use_cuda:\n",
        "#         print (\"cuda\")\n",
        "        image.cuda()         \n",
        "    return image  \n",
        "\n",
        "def testModel(test_dir, local_model):    \n",
        "    if use_cuda:\n",
        "        local_model.cuda()\n",
        "    \n",
        "    local_model.eval()\n",
        "    \n",
        "    columns = ['file', 'species']\n",
        "    df_pred = pd.DataFrame(data=np.zeros((0, len(columns))), columns=columns)\n",
        "#     df_pred.species.astype(int)\n",
        "    for index, row in (sample_submission.iterrows()):\n",
        "#         for file in os.listdir(test_dir):            \n",
        "        currImage=os.path.join(test_dir, row['file'])\n",
        "        if os.path.isfile(currImage):\n",
        "            X_tensor_test=testImageLoader (currImage)            \n",
        "#             print (type(X_tensor_test))\n",
        "#             if use_cuda:\n",
        "#                 X_tensor_test = Variable(X_tensor_test.cuda()) \n",
        "#             else:\n",
        "#                 X_tensor_test = Variable(X_tensor_test)        \n",
        "            \n",
        "            # get the index of the max log-probability\n",
        "            predicted_val = (local_model(X_tensor_test)).data.max(1)[1] # get the index of the max log-probability\n",
        "#             predicted_val = predicted_val.data.max(1, keepdim=True)[1]\n",
        "            p_test = (predicted_val.cpu().numpy().item())\n",
        "            df_pred = df_pred.append({'file': row['file'], 'species': num_to_class[int(p_test)]}, ignore_index=True)             \n",
        "    \n",
        "    return df_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9qG7J9RiBCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':  \n",
        "    \n",
        "    epochs=5\n",
        "    runId = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')    \n",
        "    recorder = RecorderMeter(epochs)  # epoc is updated\n",
        "#     model_name = (type(model).__name__)\n",
        "\n",
        "    exp_name = datetime.datetime.now().strftime(model_name + '_' + dataset + '_%Y-%m-%d_%H-%M-%S')    \n",
        "    mPath = './logs' + '/' + dataset + '/' + model_name + '/'    \n",
        "    if not os.path.isdir(mPath):\n",
        "        os.makedirs(mPath)    \n",
        "    print(\"Random Seed: {}\".format(manualSeed))\n",
        "    print(\"python version : {}\".format(sys.version.replace('\\n', ' ')))\n",
        "    print(\"torch  version : {}\".format(torch.__version__))\n",
        "    print(\"cudnn  version : {}\".format(torch.backends.cudnn.version()))    \n",
        "    print(\"=> Final model name '{}'\".format(model_name))            \n",
        "    print (\"MODEL: {}\".format( str(model_name)))\n",
        "    print (\"dataset: {}\".format(dataset))\n",
        "    print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))    \n",
        "    \n",
        "    print (\"MODEL: {}\".format( str(type(model).__name__)))\n",
        "    \n",
        "    start_training_time = time.time()\n",
        "    training_time=time.time()\n",
        "    for epoch in tqdm(range(0, epochs)):        \n",
        "        train_result, accuracy_tr=train(t_loader, model, epoch, optimizer)\n",
        "        val_loss, val_accuracy= validate(v_loader, model, epoch)  \n",
        "        \n",
        "        recorder.update(epoch, train_result, accuracy_tr, val_loss, val_accuracy) \n",
        "        training_time=time.time() - start_training_time\n",
        "        recorder.plot_curve2(os.path.join(mPath, model_name + '_' + exp_name + '.png'),training_time, model, model_name,\n",
        "                            str(dataset_sizes),\n",
        "                        batch_size, lr,dataset,manualSeed,len(classes))\n",
        "        \n",
        "        if float(val_accuracy) > float(0.0):            \n",
        "            print (\"EARLY STOP\")                        \n",
        "#             torch.save(model.state_dict(), os.path.join(mPath, model_name + '_' + runId + '_' + str(val_accuracy) + '_.pth'))                        \n",
        "            torch.save(model.state_dict(),os.path.join(mPath, model_name + '_'  + str(val_accuracy) + '_' + str (epoch) + '_' + runId  + '_.pth'))\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy9HhQOjiCZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 7)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "lr= 0.005 * 2 * 2\n",
        "# optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9,\n",
        "                              weight_decay=0.0005, nesterov=True)\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "    \n",
        "model.load_state_dict(torch.load('./logs/ISIC2018_Task3_Training_Input/ResNet/ResNet_83.070452_5_2019-05-19_06-13-35_.pth'))\n",
        "model.eval()\n",
        "\n",
        "# val_preds,val_labels = validate2(v_loader,model,1)\n",
        "val_preds,val_labels=[],[]\n",
        "with torch.no_grad():\n",
        "    for i, (images, labels) in enumerate(v_loader):\n",
        "        model.cuda()\n",
        "        val_preds.append(model(images.cuda()).cpu().numpy())\n",
        "        val_labels.append(labels.cpu().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3HEMPvFiDQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "plt.figure(figsize=(7,7))\n",
        "y_true,y_pred = np.concatenate(val_labels),np.concatenate([np.argmax(val_preds[i],1) for i in range(len(val_preds))])\n",
        "fig = sns.heatmap(confusion_matrix(y_true,y_pred),cmap='RdBu',annot=True,linewidths=.25,linecolor='black')\n",
        "fig.set_xlabel('actuals',fontsize=14)\n",
        "fig.set_ylabel('predictions',fontsize=14)\n",
        "\n",
        "print(classification_report(y_true,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOcwiKcbiGov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train last layer only\n",
        "#plot lime explanation of decision pixels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntlDcjPtiHtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.requires_grad = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlH6hhd3iIm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fc.weight.requires_grad = True\n",
        "model.fc.bias.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rHe4iYziJpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':  \n",
        "    model_name = (type(model).__name__)\n",
        "    epochs=5\n",
        "    runId = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')    \n",
        "    recorder = RecorderMeter(epochs)  # epoc is updated\n",
        "#     model_name = (type(model).__name__)\n",
        "\n",
        "    exp_name = datetime.datetime.now().strftime(model_name + '_' + dataset + '_%Y-%m-%d_%H-%M-%S')    \n",
        "    mPath = './logs' + '/' + dataset + '/' + model_name + '/'    \n",
        "    if not os.path.isdir(mPath):\n",
        "        os.makedirs(mPath)    \n",
        "    print(\"Random Seed: {}\".format(manualSeed))\n",
        "    print(\"python version : {}\".format(sys.version.replace('\\n', ' ')))\n",
        "    print(\"torch  version : {}\".format(torch.__version__))\n",
        "    print(\"cudnn  version : {}\".format(torch.backends.cudnn.version()))    \n",
        "    print(\"=> Final model name '{}'\".format(model_name))            \n",
        "    print (\"MODEL: {}\".format( str(model_name)))\n",
        "    print (\"dataset: {}\".format(dataset))\n",
        "    print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))    \n",
        "    \n",
        "    print (\"MODEL: {}\".format( str(type(model).__name__)))\n",
        "    \n",
        "    start_training_time = time.time()\n",
        "    training_time=time.time()\n",
        "    for epoch in tqdm(range(0, epochs)):        \n",
        "        train_result, accuracy_tr=train(t_loader, model, epoch, optimizer)\n",
        "        val_loss, val_accuracy= validate(v_loader, model, epoch)  \n",
        "        \n",
        "        recorder.update(epoch, train_result, accuracy_tr, val_loss, val_accuracy) \n",
        "        training_time=time.time() - start_training_time\n",
        "        recorder.plot_curve2(os.path.join(mPath, model_name + '_' + exp_name + '.png'),training_time, model, model_name,\n",
        "                            str(dataset_sizes),\n",
        "                        batch_size, lr,dataset,manualSeed,len(classes))\n",
        "        \n",
        "        if float(val_accuracy) > float(0.0):            \n",
        "            print (\"EARLY STOP\")                        \n",
        "#             torch.save(model.state_dict(), os.path.join(mPath, model_name + '_' + runId + '_' + str(val_accuracy) + '_.pth'))                        \n",
        "            torch.save(model.state_dict(),os.path.join(mPath, model_name +'update_last_layer'+ '_'  + str(val_accuracy) + '_' + str (epoch) + '_' + runId  + '_.pth'))\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh0ro2kMiLRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 7)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "lr= 0.005 * 2 * 2\n",
        "# optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9,\n",
        "                              weight_decay=0.0005, nesterov=True)\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "    \n",
        "model.load_state_dict(torch.load('./logs/ISIC2018_Task3_Training_Input/ResNet/ResNetupdate_last_layer_90.851735_4_2019-05-19_15-09-30_.pth'))\n",
        "model.eval()\n",
        "\n",
        "# val_preds,val_labels = validate2(v_loader,model,1)\n",
        "val_preds,val_labels=[],[]\n",
        "with torch.no_grad():\n",
        "    for i, (images, labels) in enumerate(v_loader):\n",
        "        model.cuda()\n",
        "        val_preds.append(model(images.cuda()).cpu().numpy())\n",
        "        val_labels.append(labels.cpu().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okyr5RfkiMXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "plt.figure(figsize=(7,7))\n",
        "y_true,y_pred = np.concatenate(val_labels),np.concatenate([np.argmax(val_preds[i],1) for i in range(len(val_preds))])\n",
        "fig = sns.heatmap(confusion_matrix(y_true,y_pred),cmap='RdBu',annot=True,linewidths=.25,linecolor='black')\n",
        "fig.set_xlabel('actuals',fontsize=14)\n",
        "fig.set_ylabel('predictions',fontsize=14)\n",
        "\n",
        "print(classification_report(y_true,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1cyOoVqiRxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "# wrapper around imgaug so it is compatible with pytorch transforms format\n",
        "class ImgAugTransform:\n",
        "    def __init__(self, aug):\n",
        "        self.aug = aug\n",
        "      \n",
        "    def __call__(self, img):\n",
        "        img = np.array(img)\n",
        "        return Image.fromarray(np.uint8(self.aug.augment_image(img)))\n",
        "  \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' ' + str(self.aug)\n",
        "    \n",
        "class DrawShape:\n",
        "\n",
        "    def __call__(self, img):\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        corner = np.random.randint(1,5)\n",
        "        coord = ((np.random.randint(0,img.size[0]/8) + img.size[0]/2* (corner==2 or corner==4), np.random.randint(0,img.size[1]/8 + img.size[0]/2* (corner==3 or corner==4))), \n",
        "                        (np.random.randint(0,img.size[0]/2) + img.size[0]/2* (corner==2 or corner==4), np.random.randint(0,img.size[1]/2 + img.size[0]/2* (corner==3 or corner==4))))\n",
        "        if np.random.rand()<0.5:\n",
        "            draw.ellipse(coord, fill=np.random.randint(0,240))\n",
        "        else:\n",
        "            draw.rectangle(coord, fill=np.random.randint(0,240))\n",
        "        del draw\n",
        "        return img\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}